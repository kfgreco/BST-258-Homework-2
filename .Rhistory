scale_color_manual(values = c("Sharp Null" = "cornflowerblue", "Weak Null" = "coral")) +
theme_minimal() +
labs(x = "Sample Size", y = "Power",
title = "Power of Tests for Sharp vs. Weak Null")
plot
library(fastverse)
library(tidyverse)
library(patchwork)
library(ggsci)
# Parameters
n1 <- c(10, 25, 50, 100, 250)
n0 <- c(10, 25, 50, 100, 250)
n_sim <- 1000
# Set number of permutations (B) and significance level (alpha)
B <- 100L
alpha <- 0.05
# Simulation function
sim <- function(n1, n0, B, alpha) {
# Placeholder for p-values
pval_sharp <- numeric(n_sim)
pval_weak <- numeric(n_sim)
for (i in 1:n_sim) {
# Randomize treatment
A <- sample(c(rep(1, n1), rep(0, n0)))
# Generate outcomes
Y1 <- rnorm(n1, mean = 1/10, sd = sqrt(1/16))
Y0 <- rnorm(n0, mean = 0, sd = sqrt(1/16))
Y <- A * Y1 + (1 - A) * Y0
# Observed value of difference-in-means test statistic
t_obs <- abs(mean(Y[A == 1]) - mean(Y[A == 0]))
# Testing under the sharp null
# Generate null distribution of test statistic under sharp null hypothesis
# Permute treatment assignment B times
t_null <- lapply(seq_len(B), function(j) {
# Randomly permute treatment assignments
A_perm <- sample(A)
# Calculate test statistic under the permuted treatment assignments
t_perm <- abs(mean(Y[A_perm == 1]) - mean(Y[A_perm == 0]))
# Return test statistic for each permutation
return(t_perm)
})
t_null <- do.call(c, t_null)
pval_sharp[i] <- mean(t_null >= t_obs)
# Testing under the weak null
pval_weak[i] <- z.test(Y ~ A)$p.value
}
# Power calculation
power_sharp <- mean(pval_sharp < alpha)
power_weak <- mean(pval_weak < alpha)
return(list(power_sharp = power_sharp, power_weak = power_weak))
}
results <- Map(sim, n1, n0, MoreArgs = list(B = B, alpha = alpha))
# Import codified data
codes <- read.csv("codified", header=TRUE)
library(Matrix)
df <- read.csv("patient_level_codes.csv")
df <- read.csv("patient_level_codes.csv")
# If pa
head(df)
library(Matrix)
df <- read.csv("patient_level_codes.csv")
head(df)
names(df)["patient_num"] <- "patient"
names(df)
?rename
df <- df %>%
rename(patient = patient_num, code = parent_code)
library(dplyr)
df <- df %>%
rename(patient = patient_num, code = parent_code)
names(df)
class(df$code)
head(df)
df$code <- as.numeric(as.factor(df$code))
df$code
library(Matrix)
library(dplyr)
df <- read.csv("patient_level_codes.csv")
head(df)
df <- df %>% rename(patient = patient_num, code = parent_code)
head(df)
patient_num <- as.numeric(as.factor(df$patient_num))
patient_num
patient_num <- as.numeric(as.factor(df$patient_num))
patient_num
patient <- as.numeric(as.factor(df$patient))
patient
df$code_index <- as.numeric(as.factor(df$code))
df$patient_index <- as.numeric(as.factor(df$patient))
head(df)
sparse_matrix <- sparseMatrix(i = df$patient_index,
j = df$code_index,
x = df$count,
dims = c(max(df$patient_index), max(df$code_index)))
sparse_matrix
head(df)
patient_mapping <- levels(as.factor(df$patient))
code_mapping <- levels(as.factor(df$code))
patient_mapping
code_mapping
View(df)
head(df)
rownames(sparse_matrix) <- patient_mapping[df$patient_index]
nrow(nhefs)
nhefs <- read.csv("data/nhefs.csv")
# Remove patients with missing outcome data (final n=1566)
nhefs <- nhefs[!is.na(nhefs$wt82_71), ]
nrow(nhefs)
# Fit linear outcome regression model
outcome.mod <- lm(wt82_71 ~ qsmk + sex + age + I(age^2) + race + factor(education) + smokeintensity + I(smokeintensity^2) + smokeyrs + I(smokeyrs^2) + factor(active) + factor(exercise) + wt71 + I(wt71^2) + qsmk:smokeintensity,
data = nhefs)
summary(outcome.mod)
# Predict expected outcomes under treatment and control for each individual
nhefs$ma_hat <- predict(outcome.mod, newdata = nhefs)
nhefs$m1_hat <- predict(outcome.mod, newdata = transform(nhefs, qsmk = 1))
nhefs$m0_hat <- predict(outcome.mod, newdata = transform(nhefs, qsmk = 0))
#| echo: false
#| message: false
#| label: global-setup
library(here)
# Import data
nhefs <- read.csv("data/nhefs.csv")
# Remove individuals with missing outcome data (n=1566)
nhefs <- nhefs[!is.na(nhefs$wt82_71), ]
# Fit logisitc propensity score model
ps.mod <- glm(qsmk ~ sex + age + I(age^2) + race + factor(education) + smokeintensity + I(smokeintensity^2) + smokeyrs + I(smokeyrs^2) + factor(active) + factor(exercise) + wt71 + I(wt71^2),
data = nhefs,
family = binomial)
# Estimate propensity scores
nhefs$phat <- predict(ps.mod, nhefs, "response")
# Calculate inverse probability weights
nhefs$ipw <- ifelse(nhefs$qsmk == 1, 1/nhefs$phat, 1/(1 - nhefs$phat))
mean_ipw <- round(mean(nhefs$ipw),2)
min_ipw <- round(min(nhefs$ipw),2)
max_ipw <- round(max(nhefs$ipw),2)
cat(sprintf("Mean of IP weights: %0.2f\n", mean_ipw))
cat(sprintf("Minimum of IP weights: %0.2f\n", min_ipw))
cat(sprintf("Maximum of IP weights: %0.2f\n", max_ipw))
# Calculate stabilized weights
p_treatment <- mean(nhefs$qsmk)
nhefs$sw <- ifelse(nhefs$qsmk == 1, p_treatment/nhefs$phat, (1 - p_treatment)/(1 - nhefs$phat))
mean_sw <- round(mean(nhefs$sw),2)
min_sw <- round(min(nhefs$sw),2)
max_sw <- round(max(nhefs$sw),2)
cat(sprintf("Mean of standardized weights: %0.2f\n", mean_sw))
cat(sprintf("Minimum of standardized weights: %0.2f\n", min_sw))
cat(sprintf("Maximum of standardized weights: %0.2f\n", max_sw))
# Plot distribution of IPWs and stabilized weights
library(ggplot2)
ggplot(nhefs) +
geom_histogram(aes(x = ipw, fill = "IP Weights"), bins = 40, alpha = 0.6, position = 'identity') +
geom_histogram(aes(x = sw, fill = "Stabilized IP Weights"), bins = 40, alpha = 0.6, position = 'identity') +
labs(x = "Weights", y = "", title = "Histogram of IP Weights vs. Stabilized IP Weights") +
scale_fill_manual("",
breaks = c("IP Weights", "Stabilized IP Weights"),
values = c("IP Weights" = "cornflowerblue", "Stabilized IP Weights" = "coral2")) +
theme_minimal()
# Estimate ATE via WLS using IP weights
model_ipw <- lm(wt82_71 ~ qsmk, data = nhefs, weights = ipw)
# Extract results
qsmk_coeff <- round(summary(model_ipw)$coefficients["qsmk", "Estimate"],4)
qsmk_se <- round(summary(model_ipw)$coefficients["qsmk", "Std. Error"],4)
cat(sprintf("IPW Coefficient for qsmk: %0.4f, Non-Robust SE: %0.4f\n, Robust SE: see part (c)", qsmk_coeff, qsmk_se))
# Estimate ATE via WLS using stabilized weights
model_sw <- lm(wt82_71 ~ qsmk, data = nhefs, weights = sw)
# Extract results
qsmk_coeff <- round(summary(model_sw)$coefficients["qsmk", "Estimate"],4)
qsmk_se <- round(summary(model_sw)$coefficients["qsmk", "Std. Error"],4)
cat(sprintf("SW Coefficient for qsmk: %0.4f, Non-Robust SE: %0.4f\n, Robust SE: see part (c)", qsmk_coeff, qsmk_se))
# Set bootstrap parameters
set.seed(2024)
n_bootstraps <- 1000
ate_ipw_bootstraps <- numeric(n_bootstraps)
ate_sw_bootstraps <- numeric(n_bootstraps)
for (i in 1:n_bootstraps) {
# Resample with replacement
sampled_indices <- sample(nrow(nhefs), replace = TRUE)
bootstrap_sample <- nhefs[sampled_indices, ]
# Recalculate weights based on the bootstrap sample
# IP weights
bootstrap_sample$ipw <- ifelse(bootstrap_sample$qsmk == 1, 1/bootstrap_sample$phat, 1/(1 - bootstrap_sample$phat))
# Stabilized IP weights
p_treatment_bootstrap <- mean(bootstrap_sample$qsmk)
bootstrap_sample$sw <- ifelse(bootstrap_sample$qsmk == 1, p_treatment_bootstrap/bootstrap_sample$phat, (1 - p_treatment_bootstrap)/(1 - bootstrap_sample$phat))
# Fit linear outcome models and calculate ATE for IPW and SW
model_ipw_bs <- lm(wt82_71 ~ qsmk, data = bootstrap_sample, weights = bootstrap_sample$ipw)
model_sw_bs <- lm(wt82_71 ~ qsmk, data = bootstrap_sample, weights = bootstrap_sample$sw)
ate_ipw_bootstraps[i] <- coef(model_ipw_bs)["qsmk"]
ate_sw_bootstraps[i] <- coef(model_sw_bs)["qsmk"]
}
# Plot bootstrap distribution
ggplot(data.frame(ate_ipw_bootstraps), aes(x = ate_ipw_bootstraps)) +
geom_histogram(binwidth = .1, fill = "cornflowerblue", color = "black") +
theme_minimal() +
labs(title = "Distribution of IPW/SW Bootstrap Estimates of ATE",
x = "ATE Estimator Values",
y = "Frequency")
# Method 1 (normal-based) for constructing bootstrap CI
# Estimate the standard error of the IPW estimator
se_ipw <- sd(ate_ipw_bootstraps)
print(paste("Bootstrap standard error [IPW]:", round(se_ipw,4)))
# Estimate the standard error of the SW estimator
se_sw <- sd(ate_sw_bootstraps)
print(paste("Bootstrap standard error [S-IPW]:", round(se_sw,4)))
# Construct 95% Confidence Interval for the ATE
ci_lower <- round(mean(ate_ipw_bootstraps) - qt(0.975, n_bootstraps-2) * se_ipw,4)
ci_upper <- round(mean(ate_ipw_bootstraps) + qt(0.975, n_bootstraps-2) * se_ipw,4)
print(paste("Normal-based 95% CI for ATE [IPW and S-IPW]: [", ci_lower, ",", ci_upper, "]"))
# Method 2 (quantile-based) for constructing bootstrap CI
ci_lower <- quantile(ate_ipw_bootstraps, probs = 0.025)
ci_upper <- quantile(ate_ipw_bootstraps, probs = 0.975)
print(paste("Quantile-based 95% CI for ATE [IPW and S-IPW]: [", round(ci_lower,4), ",", round(ci_upper,4), "]"))
library(sandwich)
library(lmtest)
# Coefficient test with robust variance estimation for IPW model
coeftest_ipw <- coeftest(model_ipw, vcov = vcovHC(model_ipw, type = "HC0"))
# Extract estimate and robust standard error for ATE
estimate_ipw <- coeftest_ipw["qsmk", "Estimate"]
std_error_ipw <- coeftest_ipw["qsmk", "Std. Error"]
print(paste("Robust standard error [IPW]:", round(std_error_ipw,4)))
# Calculate 95% CI for ATE
alpha <- 0.05
ci_lower_ipw <- estimate_ipw - qnorm(1-alpha/2) * std_error_ipw
ci_upper_ipw <- estimate_ipw + qnorm(1-alpha/2) * std_error_ipw
cat(sprintf("IP Weighted ATE Estimate: %0.4f, 95%% CI: [%0.4f, %0.4f]\n", estimate_ipw, ci_lower_ipw, ci_upper_ipw))
# Coefficient test with robust variance estimation for SW model
coeftest_sw <- coeftest(model_sw, vcov = vcovHC(model_sw, type = "HC0"))
# Extract the estimate and robust standard error for ATE
estimate_sw <- coeftest_sw["qsmk", "Estimate"]
std_error_sw <- coeftest_sw["qsmk", "Std. Error"]
print(paste("Robust standard error [S-IPW]:", round(std_error_sw,4)))
# Calculate 95% CI for ATE
ci_lower_sw <- estimate_sw - qnorm(1-alpha/2) * std_error_sw
ci_upper_sw <- estimate_sw + qnorm(1-alpha/2) * std_error_sw
cat(sprintf("Stabilized IP Weighted ATE Estimate: %0.4f, 95%% CI: [%0.4f, %0.4f]\n", estimate_sw, ci_lower_sw, ci_upper_sw))
# Fit linear outcome regression model
outcome.mod <- lm(wt82_71 ~ qsmk + sex + age + I(age^2) + race + factor(education) + smokeintensity + I(smokeintensity^2) + smokeyrs + I(smokeyrs^2) + factor(active) + factor(exercise) + wt71 + I(wt71^2) + qsmk:smokeintensity,
data = nhefs)
summary(outcome.mod)
# Predict expected outcomes under treatment and control for each individual
nhefs$ma_hat <- predict(outcome.mod, newdata = nhefs)
nhefs$m1_hat <- predict(outcome.mod, newdata = transform(nhefs, qsmk = 1))
nhefs$m0_hat <- predict(outcome.mod, newdata = transform(nhefs, qsmk = 0))
# Extract and rename variables
dat_pred <- with(nhefs, data.frame(
m1_hat = m1_hat,
m0_hat = m0_hat,
ma_hat = ma_hat,
p = phat,
Y = wt82_71,
A = qsmk
))
# Compute doubly robust estimate
psi_dr <- with(dat_pred, mean((A / p - (1 - A) / (1 - p)) * (Y - ma_hat) + (m1_hat - m0_hat)))
round(psi_dr,4)
#| echo: false
#| message: false
#| label: global-setup
library(here)
# Import data
nhefs <- read.csv("data/nhefs.csv")
# Remove individuals with missing outcome data (n=1566)
nhefs <- nhefs[!is.na(nhefs$wt82_71), ]
# Fit logisitc propensity score model
ps.mod <- glm(qsmk ~ sex + age + I(age^2) + race + factor(education) + smokeintensity + I(smokeintensity^2) + smokeyrs + I(smokeyrs^2) + factor(active) + factor(exercise) + wt71 + I(wt71^2),
data = nhefs,
family = binomial)
# Estimate propensity scores
nhefs$phat <- predict(ps.mod, nhefs, "response")
# Calculate inverse probability weights
nhefs$ipw <- ifelse(nhefs$qsmk == 1, 1/nhefs$phat, 1/(1 - nhefs$phat))
mean_ipw <- round(mean(nhefs$ipw),2)
min_ipw <- round(min(nhefs$ipw),2)
max_ipw <- round(max(nhefs$ipw),2)
cat(sprintf("Mean of IP weights: %0.2f\n", mean_ipw))
cat(sprintf("Minimum of IP weights: %0.2f\n", min_ipw))
cat(sprintf("Maximum of IP weights: %0.2f\n", max_ipw))
# Calculate stabilized weights
p_treatment <- mean(nhefs$qsmk)
nhefs$sw <- ifelse(nhefs$qsmk == 1, p_treatment/nhefs$phat, (1 - p_treatment)/(1 - nhefs$phat))
mean_sw <- round(mean(nhefs$sw),2)
min_sw <- round(min(nhefs$sw),2)
max_sw <- round(max(nhefs$sw),2)
cat(sprintf("Mean of standardized weights: %0.2f\n", mean_sw))
cat(sprintf("Minimum of standardized weights: %0.2f\n", min_sw))
cat(sprintf("Maximum of standardized weights: %0.2f\n", max_sw))
# Plot distribution of IPWs and stabilized weights
library(ggplot2)
ggplot(nhefs) +
geom_histogram(aes(x = ipw, fill = "IP Weights"), bins = 40, alpha = 0.6, position = 'identity') +
geom_histogram(aes(x = sw, fill = "Stabilized IP Weights"), bins = 40, alpha = 0.6, position = 'identity') +
labs(x = "Weights", y = "", title = "Histogram of IP Weights vs. Stabilized IP Weights") +
scale_fill_manual("",
breaks = c("IP Weights", "Stabilized IP Weights"),
values = c("IP Weights" = "cornflowerblue", "Stabilized IP Weights" = "coral2")) +
theme_minimal()
# Estimate ATE via WLS using IP weights
model_ipw <- lm(wt82_71 ~ qsmk, data = nhefs, weights = ipw)
# Extract results
qsmk_coeff <- round(summary(model_ipw)$coefficients["qsmk", "Estimate"],4)
qsmk_se <- round(summary(model_ipw)$coefficients["qsmk", "Std. Error"],4)
cat(sprintf("IPW Coefficient for qsmk: %0.4f, Non-Robust SE: %0.4f\n, Robust SE: see part (c)", qsmk_coeff, qsmk_se))
# Estimate ATE via WLS using stabilized weights
model_sw <- lm(wt82_71 ~ qsmk, data = nhefs, weights = sw)
# Extract results
qsmk_coeff <- round(summary(model_sw)$coefficients["qsmk", "Estimate"],4)
qsmk_se <- round(summary(model_sw)$coefficients["qsmk", "Std. Error"],4)
cat(sprintf("SW Coefficient for qsmk: %0.4f, Non-Robust SE: %0.4f\n, Robust SE: see part (c)", qsmk_coeff, qsmk_se))
# Set bootstrap parameters
set.seed(2024)
n_bootstraps <- 1000
ate_ipw_bootstraps <- numeric(n_bootstraps)
ate_sw_bootstraps <- numeric(n_bootstraps)
for (i in 1:n_bootstraps) {
# Resample with replacement
sampled_indices <- sample(nrow(nhefs), replace = TRUE)
bootstrap_sample <- nhefs[sampled_indices, ]
# Recalculate weights based on the bootstrap sample
# IP weights
bootstrap_sample$ipw <- ifelse(bootstrap_sample$qsmk == 1, 1/bootstrap_sample$phat, 1/(1 - bootstrap_sample$phat))
# Stabilized IP weights
p_treatment_bootstrap <- mean(bootstrap_sample$qsmk)
bootstrap_sample$sw <- ifelse(bootstrap_sample$qsmk == 1, p_treatment_bootstrap/bootstrap_sample$phat, (1 - p_treatment_bootstrap)/(1 - bootstrap_sample$phat))
# Fit linear outcome models and calculate ATE for IPW and SW
model_ipw_bs <- lm(wt82_71 ~ qsmk, data = bootstrap_sample, weights = bootstrap_sample$ipw)
model_sw_bs <- lm(wt82_71 ~ qsmk, data = bootstrap_sample, weights = bootstrap_sample$sw)
ate_ipw_bootstraps[i] <- coef(model_ipw_bs)["qsmk"]
ate_sw_bootstraps[i] <- coef(model_sw_bs)["qsmk"]
}
# Plot bootstrap distribution
ggplot(data.frame(ate_ipw_bootstraps), aes(x = ate_ipw_bootstraps)) +
geom_histogram(binwidth = .1, fill = "cornflowerblue", color = "black") +
theme_minimal() +
labs(title = "Distribution of IPW/SW Bootstrap Estimates of ATE",
x = "ATE Estimator Values",
y = "Frequency")
# Method 1 (normal-based) for constructing bootstrap CI
# Estimate the standard error of the IPW estimator
se_ipw <- sd(ate_ipw_bootstraps)
print(paste("Bootstrap standard error [IPW]:", round(se_ipw,4)))
# Estimate the standard error of the SW estimator
se_sw <- sd(ate_sw_bootstraps)
print(paste("Bootstrap standard error [S-IPW]:", round(se_sw,4)))
# Construct 95% Confidence Interval for the ATE
ci_lower <- round(mean(ate_ipw_bootstraps) - qt(0.975, n_bootstraps-2) * se_ipw,4)
ci_upper <- round(mean(ate_ipw_bootstraps) + qt(0.975, n_bootstraps-2) * se_ipw,4)
print(paste("Normal-based 95% CI for ATE [IPW and S-IPW]: [", ci_lower, ",", ci_upper, "]"))
# Method 2 (quantile-based) for constructing bootstrap CI
ci_lower <- quantile(ate_ipw_bootstraps, probs = 0.025)
ci_upper <- quantile(ate_ipw_bootstraps, probs = 0.975)
print(paste("Quantile-based 95% CI for ATE [IPW and S-IPW]: [", round(ci_lower,4), ",", round(ci_upper,4), "]"))
library(sandwich)
library(lmtest)
# Coefficient test with robust variance estimation for IPW model
coeftest_ipw <- coeftest(model_ipw, vcov = vcovHC(model_ipw, type = "HC0"))
# Extract estimate and robust standard error for ATE
estimate_ipw <- coeftest_ipw["qsmk", "Estimate"]
std_error_ipw <- coeftest_ipw["qsmk", "Std. Error"]
print(paste("Robust standard error [IPW]:", round(std_error_ipw,4)))
# Calculate 95% CI for ATE
alpha <- 0.05
ci_lower_ipw <- estimate_ipw - qnorm(1-alpha/2) * std_error_ipw
ci_upper_ipw <- estimate_ipw + qnorm(1-alpha/2) * std_error_ipw
cat(sprintf("IP Weighted ATE Estimate: %0.4f, 95%% CI: [%0.4f, %0.4f]\n", estimate_ipw, ci_lower_ipw, ci_upper_ipw))
# Coefficient test with robust variance estimation for SW model
coeftest_sw <- coeftest(model_sw, vcov = vcovHC(model_sw, type = "HC0"))
# Extract the estimate and robust standard error for ATE
estimate_sw <- coeftest_sw["qsmk", "Estimate"]
std_error_sw <- coeftest_sw["qsmk", "Std. Error"]
print(paste("Robust standard error [S-IPW]:", round(std_error_sw,4)))
# Calculate 95% CI for ATE
ci_lower_sw <- estimate_sw - qnorm(1-alpha/2) * std_error_sw
ci_upper_sw <- estimate_sw + qnorm(1-alpha/2) * std_error_sw
cat(sprintf("Stabilized IP Weighted ATE Estimate: %0.4f, 95%% CI: [%0.4f, %0.4f]\n", estimate_sw, ci_lower_sw, ci_upper_sw))
# Fit linear outcome regression model
outcome.mod <- lm(wt82_71 ~ qsmk + sex + age + I(age^2) + race + factor(education) + smokeintensity + I(smokeintensity^2) + smokeyrs + I(smokeyrs^2) + factor(active) + factor(exercise) + wt71 + I(wt71^2) + qsmk:smokeintensity,
data = nhefs)
summary(outcome.mod)
# Predict expected outcomes under treatment and control for each individual
nhefs$ma_hat <- predict(outcome.mod, newdata = nhefs)
nhefs$m1_hat <- predict(outcome.mod, newdata = transform(nhefs, qsmk = 1))
nhefs$m0_hat <- predict(outcome.mod, newdata = transform(nhefs, qsmk = 0))
# Extract and rename variables
dat_pred <- with(nhefs, data.frame(
m1_hat = m1_hat,
m0_hat = m0_hat,
ma_hat = ma_hat,
p = phat,
Y = wt82_71,
A = qsmk
))
# Compute doubly robust estimate
psi_dr <- with(dat_pred, mean((A / p - (1 - A) / (1 - p)) * (Y - ma_hat) + (m1_hat - m0_hat)))
# Set bootstrap parameters
set.seed(2024)
n_bootstraps <- 1000
psi_dr_bootstraps <- numeric(n_bootstraps)
for (i in 1:n_bootstraps) {
# Resample with replacement
sample_indices <- sample(nrow(dat_pred), replace = TRUE)
bootstrap_sample <- dat_pred[sample_indices, ]
# Recalculate DR estimator for the bootstrap sample
psi_dr_bootstrap <- with(bootstrap_sample, mean((A / p - (1 - A) / (1 - p)) * (Y - ma_hat) + (m1_hat - m0_hat)))
psi_dr_bootstraps[i] <- psi_dr_bootstrap
}
# Plot bootstrap distribution
ggplot(data.frame(psi_dr_bootstraps), aes(x = psi_dr_bootstraps)) +
geom_histogram(binwidth = .1, fill = "cornflowerblue", color = "black") +
theme_minimal() +
labs(title = "Distribution of DR Estimator Bootstrap Estimates",
x = "DR Estimator Values",
y = "Frequency")
# Method 1 (normal-based) for constructing bootstrap CI
# Estimate the standard error of the DR estimator
se_psi_dr <- sd(psi_dr_bootstraps)
print(paste("Bootstrap standard error [DR]:", round(se_psi_dr,4)))
# Construct 95% Confidence Interval for the ATE
ci_lower <- round(mean(psi_dr_bootstraps) - qt(0.975, n_bootstraps-2) * se_psi_dr,4)
ci_upper <- round(mean(psi_dr_bootstraps) + qt(0.975, n_bootstraps-2) * se_psi_dr,4)
print(paste("Normal-based 95% CI for ATE [DR]: [", ci_lower, ",", ci_upper, "]"))
# Method 2 (quantile-based) for constructing bootstrap CI
ci_lower <- quantile(psi_dr_bootstraps, probs = 0.025)
ci_upper <- quantile(psi_dr_bootstraps, probs = 0.975)
print(paste("Quantile-based 95% CI for ATE [DR]: [", round(ci_lower,4), ",", round(ci_upper,4), "]"))
psi_dr
round(psi_dr,4)
qsmk_coeff
round(se_psi_dr,4)
# Estimate ATE via WLS using IP weights
model_ipw <- lm(wt82_71 ~ qsmk, data = nhefs, weights = ipw)
# Extract results
qsmk_coeff <- round(summary(model_ipw)$coefficients["qsmk", "Estimate"],4)
qsmk_se <- round(summary(model_ipw)$coefficients["qsmk", "Std. Error"],4)
cat(sprintf("IPW Coefficient for qsmk: %0.4f, Non-Robust SE: %0.4f\n, Robust SE: see part (c)", qsmk_coeff, qsmk_se))
# Estimate ATE via WLS using stabilized weights
model_sw <- lm(wt82_71 ~ qsmk, data = nhefs, weights = sw)
# Extract results
qsmk_coeff <- round(summary(model_sw)$coefficients["qsmk", "Estimate"],4)
qsmk_se <- round(summary(model_sw)$coefficients["qsmk", "Std. Error"],4)
cat(sprintf("SW Coefficient for qsmk: %0.4f, Non-Robust SE: %0.4f\n, Robust SE: see part (c)", qsmk_coeff, qsmk_se))
round(se_ipw,4)
# Fit linear outcome regression model
outcome.mod <- lm(wt82_71 ~ qsmk + sex + age + I(age^2) + race + factor(education) + smokeintensity + I(smokeintensity^2) + smokeyrs + I(smokeyrs^2) + factor(active) + factor(exercise) + wt71 + I(wt71^2) + qsmk:smokeintensity,
data = nhefs)
# Predict expected outcomes under treatment and control for each individual
nhefs$ma_hat <- predict(outcome.mod, newdata = nhefs)
nhefs$m1_hat <- predict(outcome.mod, newdata = transform(nhefs, qsmk = 1))
nhefs$m0_hat <- predict(outcome.mod, newdata = transform(nhefs, qsmk = 0))
# Extract and rename variables
dat_pred <- with(nhefs, data.frame(
m1_hat = m1_hat,
m0_hat = m0_hat,
ma_hat = ma_hat,
p = phat, # OR mean(nhefs$qsmk) for DR?
Y = wt82_71,
A = qsmk
))
# Compute plug-in estimate
psi_pi <- with(dat_pred, mean(m1_hat - m0_hat))
psi_pi
round(psi_pi,4)
# Fit linear outcome regression model
outcome.mod <- lm(wt82_71 ~ qsmk + sex + age + I(age^2) + race + factor(education) + smokeintensity + I(smokeintensity^2) + smokeyrs + I(smokeyrs^2) + factor(active) + factor(exercise) + wt71 + I(wt71^2) + qsmk:smokeintensity,
data = nhefs)
# Predict expected outcomes under treatment and control for each individual
nhefs$ma_hat <- predict(outcome.mod, newdata = nhefs)
nhefs$m1_hat <- predict(outcome.mod, newdata = transform(nhefs, qsmk = 1))
nhefs$m0_hat <- predict(outcome.mod, newdata = transform(nhefs, qsmk = 0))
# Extract and rename variables
dat_pred <- with(nhefs, data.frame(
m1_hat = m1_hat,
m0_hat = m0_hat,
ma_hat = ma_hat,
p = phat, # OR mean(nhefs$qsmk) for DR?
Y = wt82_71,
A = qsmk
))
# Compute plug-in estimate
psi_pi <- with(dat_pred, mean(m1_hat - m0_hat))
print(paste("Point Estimate:", psi_pi))
print(paste("Point Estimate:", round(psi_pi,4)))
# Compute doubly robust estimate
psi_dr <- with(dat_pred, mean((A / p - (1 - A) / (1 - p)) * (Y - ma_hat) + (m1_hat - m0_hat)))
round(psi_dr,4)
# Get standard error & analytic 95% CIs
dat_pred
aipw_scores <- with(dat_pred, (A / p - (1 - A) / (1 - p)) * (Y - ma_hat) + (m1_hat - m0_hat))
aipw_scores
aipw_scores <- with(dat_pred, (A / p - (1 - A) / (1 - p)) * (Y - ma_hat) + (m1_hat - m0_hat))
# Compute variance and SE of AIPW scores
var_aipw <- var(aipw_scores)
se_dr <- sqrt(var_aipw / length(aipw_scores))
ci_lower <- psi_dr - 1.96 * se_dr
ci_upper <- psi_dr + 1.96 * se_dr
ci_lower
ci_upper
# Compute doubly robust estimate
psi_dr <- with(dat_pred, mean((A / p - (1 - A) / (1 - p)) * (Y - ma_hat) + (m1_hat - m0_hat)))
print(paste("Point Estimate:", round(psi_dr,4)))
# Standard error & analytic 95% confidence intervals
# Compute the AIPW scores
aipw_scores <- with(dat_pred, (A / p - (1 - A) / (1 - p)) * (Y - ma_hat) + (m1_hat - m0_hat))
# Compute variance and SE of AIPW scores
var_aipw <- var(aipw_scores)
se_dr <- sqrt(var_aipw / length(aipw_scores))
# Compute the 95% confidence interval
ci_lower <- psi_dr - 1.96 * se_dr
ci_upper <- psi_dr + 1.96 * se_dr
# Print the results
print(paste("Point Estimate:", round(psi_dr, 4)))
print(paste("Estimated Standard Error:", round(se_dr, 4)))
print(paste("95% Confidence Interval: [", round(ci_lower, 4), ",", round(ci_upper, 4), "]"))
